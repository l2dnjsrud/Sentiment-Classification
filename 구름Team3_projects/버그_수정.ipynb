{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"버그_수정.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"92e0fbbc0a8342bbb3b23a00286f98ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7099de2448644be58fbf03b425ed7b87","IPY_MODEL_91e8a41a1078482ba2523bc8375c8dbb","IPY_MODEL_9f065b6268b242a0a893ff15351e442d"],"layout":"IPY_MODEL_9b86482d2cff4adf90c7d68fd932a8a8"}},"7099de2448644be58fbf03b425ed7b87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3732304bb3b426a96312f0e0a2ee36f","placeholder":"​","style":"IPY_MODEL_5c31cd6c166d467d8015fe525d6a00f2","value":"Downloading: 100%"}},"91e8a41a1078482ba2523bc8375c8dbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecb147a9f7f34da382368c305d09d4b9","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d076cc05031c4a1d81877364d8897f22","value":231508}},"9f065b6268b242a0a893ff15351e442d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a105ac5c7e854645bc18808fea167482","placeholder":"​","style":"IPY_MODEL_6a55011bf05643448443541e918fc689","value":" 226k/226k [00:00&lt;00:00, 538kB/s]"}},"9b86482d2cff4adf90c7d68fd932a8a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3732304bb3b426a96312f0e0a2ee36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c31cd6c166d467d8015fe525d6a00f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecb147a9f7f34da382368c305d09d4b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d076cc05031c4a1d81877364d8897f22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a105ac5c7e854645bc18808fea167482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a55011bf05643448443541e918fc689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ee8279259e34f168c8c3c864c53f856":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f777d6ffcae04f379f051551573f5c93","IPY_MODEL_b3b1a0217703407bbaf0eed450038f0c","IPY_MODEL_616f80fa94cc4a46ad5c49ab9e6a5f2b"],"layout":"IPY_MODEL_3055cd21b6e84e3bba1ff6ff124ef2a4"}},"f777d6ffcae04f379f051551573f5c93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb4bf9f570d640719dcafb63636a9f9b","placeholder":"​","style":"IPY_MODEL_b4064fc0fa7440a9b0876ffac0f2ddd7","value":"Downloading: 100%"}},"b3b1a0217703407bbaf0eed450038f0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ab4c37ef36840e2b6dcfa96e570fe9b","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_898e75596a62475aaa25a3b4437c7e3d","value":28}},"616f80fa94cc4a46ad5c49ab9e6a5f2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8398e9c882864e83b321433c065ba432","placeholder":"​","style":"IPY_MODEL_782603bcfc114911b1b5f5347ef8fed1","value":" 28.0/28.0 [00:00&lt;00:00, 856B/s]"}},"3055cd21b6e84e3bba1ff6ff124ef2a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb4bf9f570d640719dcafb63636a9f9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4064fc0fa7440a9b0876ffac0f2ddd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ab4c37ef36840e2b6dcfa96e570fe9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"898e75596a62475aaa25a3b4437c7e3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8398e9c882864e83b321433c065ba432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"782603bcfc114911b1b5f5347ef8fed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bdef5955f9f41ff8dc31fa09f886f71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3d099083bf4474297d0dfa5e71f62a9","IPY_MODEL_6e116809129246ad89c5e73edfb7bc43","IPY_MODEL_85ff8e4874cd47aab00b4da2c2b6bd82"],"layout":"IPY_MODEL_db3b13cacbd84cf5bb4f0f948d791864"}},"f3d099083bf4474297d0dfa5e71f62a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af64edaf108a421fa388b8bb673d4323","placeholder":"​","style":"IPY_MODEL_5a7c56041d9747e9b12227fa6fc97d2d","value":"Downloading: 100%"}},"6e116809129246ad89c5e73edfb7bc43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20cdbd94d4e8429b9f5b41a7e007c9fa","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bb238dba8f84bdcbadb90765d1ee2de","value":570}},"85ff8e4874cd47aab00b4da2c2b6bd82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be5ebb2e67274c76af3464b58d623731","placeholder":"​","style":"IPY_MODEL_9dbee260669d4b43a1a898821264bfdd","value":" 570/570 [00:00&lt;00:00, 18.0kB/s]"}},"db3b13cacbd84cf5bb4f0f948d791864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af64edaf108a421fa388b8bb673d4323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7c56041d9747e9b12227fa6fc97d2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20cdbd94d4e8429b9f5b41a7e007c9fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bb238dba8f84bdcbadb90765d1ee2de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be5ebb2e67274c76af3464b58d623731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dbee260669d4b43a1a898821264bfdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Import requirements"],"metadata":{"id":"TH32rzgprvgM"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"G9EvC1HBuf41","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5feadbcd-a648-4be3-df70-ae183fe3d091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 45.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 42.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","source":["import os\n","import pdb\n","import argparse\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from collections import defaultdict\n","\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    AutoConfig,\n","    AdamW\n",")"],"metadata":{"id":"AAdLxrUZrvgP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Preprocess"],"metadata":{"id":"ASWOOmXqrvgQ"}},{"cell_type":"code","source":["def make_id_file(task, tokenizer):\n","    def make_data_strings(file_name):\n","        data_strings = []\n","        with open(os.path.join(file_name), 'r', encoding='utf-8') as f:\n","            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n","        for item in id_file_data:\n","            data_strings.append(' '.join([str(k) for k in item]))\n","        return data_strings\n","    \n","    print('it will take some times...')\n","    train_pos = make_data_strings('sentiment.train.1')\n","    train_neg = make_data_strings('sentiment.train.0')\n","    dev_pos = make_data_strings('sentiment.dev.1')\n","    dev_neg = make_data_strings('sentiment.dev.0')\n","\n","    print('make id file finished!')\n","    return train_pos, train_neg, dev_pos, dev_neg"],"metadata":{"id":"RAnU6w29rvgR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"Ui2HOCflrvgR","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["92e0fbbc0a8342bbb3b23a00286f98ad","7099de2448644be58fbf03b425ed7b87","91e8a41a1078482ba2523bc8375c8dbb","9f065b6268b242a0a893ff15351e442d","9b86482d2cff4adf90c7d68fd932a8a8","a3732304bb3b426a96312f0e0a2ee36f","5c31cd6c166d467d8015fe525d6a00f2","ecb147a9f7f34da382368c305d09d4b9","d076cc05031c4a1d81877364d8897f22","a105ac5c7e854645bc18808fea167482","6a55011bf05643448443541e918fc689","0ee8279259e34f168c8c3c864c53f856","f777d6ffcae04f379f051551573f5c93","b3b1a0217703407bbaf0eed450038f0c","616f80fa94cc4a46ad5c49ab9e6a5f2b","3055cd21b6e84e3bba1ff6ff124ef2a4","bb4bf9f570d640719dcafb63636a9f9b","b4064fc0fa7440a9b0876ffac0f2ddd7","0ab4c37ef36840e2b6dcfa96e570fe9b","898e75596a62475aaa25a3b4437c7e3d","8398e9c882864e83b321433c065ba432","782603bcfc114911b1b5f5347ef8fed1","7bdef5955f9f41ff8dc31fa09f886f71","f3d099083bf4474297d0dfa5e71f62a9","6e116809129246ad89c5e73edfb7bc43","85ff8e4874cd47aab00b4da2c2b6bd82","db3b13cacbd84cf5bb4f0f948d791864","af64edaf108a421fa388b8bb673d4323","5a7c56041d9747e9b12227fa6fc97d2d","20cdbd94d4e8429b9f5b41a7e007c9fa","4bb238dba8f84bdcbadb90765d1ee2de","be5ebb2e67274c76af3464b58d623731","9dbee260669d4b43a1a898821264bfdd"]},"outputId":"f2e7e5bf-1a1e-417d-8896-3211a464449d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e0fbbc0a8342bbb3b23a00286f98ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee8279259e34f168c8c3c864c53f856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bdef5955f9f41ff8dc31fa09f886f71"}},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"4jVuK-V1uq3L","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":220},"outputId":"d078c488-8859-4f4a-8f5e-a42c32c7755f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c14e58ba-ac2e-4388-ad34-2a243e9f6fb0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c14e58ba-ac2e-4388-ad34-2a243e9f6fb0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving sentiment.dev.0 to sentiment.dev.0\n","Saving sentiment.dev.1 to sentiment.dev.1\n","Saving sentiment.train.0 to sentiment.train.0\n","Saving sentiment.train.1 to sentiment.train.1\n","Saving test_no_label.csv to test_no_label.csv\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"ttzRlY4Ov0jZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"843de4a1-aa07-440b-bff2-dbba6192787e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\t sentiment.dev.1    sentiment.train.1\n","sentiment.dev.0  sentiment.train.0  test_no_label.csv\n"]}]},{"cell_type":"code","source":["train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"],"metadata":{"id":"BAgztXIBrvgS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2c30f60-7beb-4a5e-8003-182bf426bfad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["it will take some times...\n","make id file finished!\n"]}]},{"cell_type":"code","source":["train_pos[:10]"],"metadata":{"id":"wRh2WjGRrvgS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"63babc59-41b6-4f40-8052-f68f5674f9f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['101 6581 2833 1012 102',\n"," '101 21688 8013 2326 1012 102',\n"," '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n"," '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n"," '101 1996 3095 2003 5379 1012 102',\n"," '101 2204 3347 2833 1012 102',\n"," '101 2204 2326 1012 102',\n"," '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n"," '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n"," '101 1996 2047 2846 3504 6429 1012 102']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class SentimentDataset(object):\n","    def __init__(self, tokenizer, pos, neg):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","        self.label = []\n","\n","        for pos_sent in pos:\n","            self.data += [self._cast_to_int(pos_sent.strip().split())]\n","            self.label += [[1]]\n","        for neg_sent in neg:\n","            self.data += [self._cast_to_int(neg_sent.strip().split())]\n","            self.label += [[0]]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample), np.array(self.label[index])"],"metadata":{"id":"JdpQQQMUrvgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n","dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"],"metadata":{"id":"wCz5ey8xrvgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, item in enumerate(train_dataset):\n","    print(item)\n","    if i == 10:\n","        break"],"metadata":{"id":"UuvkMczvrvgU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"afb0a1e6-142f-4a9b-f87c-ac2ac000e429"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n","(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n","(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n","        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n","(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n","       22974,  2063,  1012,   102]), array([1]))\n","(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n","(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n","(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n","(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n","       19247,  1012,   102]), array([1]))\n","(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n","        5404,  1012,   102]), array([1]))\n","(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n","(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"]}]},{"cell_type":"code","source":["def collate_fn_style(samples):\n","    input_ids, labels = zip(*samples)\n","    max_len = max(len(input_id) for input_id in input_ids)\n","    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n","\n","    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n","                             batch_first=True)\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n","         sorted_indices])\n","    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n","    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n","    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids, labels"],"metadata":{"id":"B0wRUBYSrvgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_batch_size=128\n","eval_batch_size=128\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=train_batch_size,\n","                                           shuffle=True, collate_fn=collate_fn_style,\n","                                           pin_memory=True, num_workers=2)\n","dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n","                                         shuffle=False, collate_fn=collate_fn_style,\n","                                         num_workers=2)"],"metadata":{"id":"5saagig0rvgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# random seed\n","random_seed=42\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n","model.to(device)"],"metadata":{"id":"zvFqCaCnrvgW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19a55f58-aeb5-4b44-f6c2-dd3596e01893"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["model.train()\n","learning_rate = 5e-5\n","optimizer = AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"dWwhmyMyrvgW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"afc685fe-af51-4168-dbdf-ccf6ea3350f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["def compute_acc(predictions, target_labels):\n","    return (np.array(predictions) == np.array(target_labels)).mean()"],"metadata":{"id":"MztU-L83rvgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_epoch = 3\n","lowest_valid_loss = 9999.\n","for epoch in range(train_epoch):\n","    with tqdm(train_loader, unit=\"batch\") as tepoch:\n","        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n","            tepoch.set_description(f\"Epoch {epoch}\")\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            position_ids = position_ids.to(device)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","\n","            output = model(input_ids=input_ids,\n","                           attention_mask=attention_mask,\n","                           token_type_ids=token_type_ids,\n","                           position_ids=position_ids,\n","                           labels=labels)\n","\n","            loss = output.loss\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            tepoch.set_postfix(loss=loss.item())\n","            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n","                # Evaluate the model five times per epoch\n","                with torch.no_grad():\n","                    model.eval()\n","                    valid_losses = []\n","                    predictions = []\n","                    target_labels = []\n","                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n","                                                                                                desc='Eval',\n","                                                                                                position=1,\n","                                                                                                leave=None):\n","                        input_ids = input_ids.to(device)\n","                        attention_mask = attention_mask.to(device)\n","                        token_type_ids = token_type_ids.to(device)\n","                        position_ids = position_ids.to(device)\n","                        labels = labels.to(device, dtype=torch.long)\n","\n","                        output = model(input_ids=input_ids,\n","                                       attention_mask=attention_mask,\n","                                       token_type_ids=token_type_ids,\n","                                       position_ids=position_ids,\n","                                       labels=labels)\n","\n","                        logits = output.logits\n","                        loss = output.loss\n","                        valid_losses.append(loss.item())\n","\n","                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                        batch_labels = [int(example) for example in labels]\n","\n","                        predictions += batch_predictions\n","                        target_labels += batch_labels\n","\n","                acc = compute_acc(predictions, target_labels)\n","                valid_loss = sum(valid_losses) / len(valid_losses)\n","                if lowest_valid_loss > valid_loss:\n","                    print('Acc for model which have lower valid loss: ', acc)\n","                    torch.save(model.state_dict(), \"./pytorch_model.bin\")"],"metadata":{"id":"DuZfvzpGrvgW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b670870-1f30-42ef-e20d-4f4bf3098863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 0:  20%|█▉        | 692/3463 [03:17<13:02,  3.54batch/s, loss=0.109] \n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.60it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.59it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.60it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.36it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.65it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.92it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.03it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.11it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.30it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.41it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.46it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.45it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.52it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.55it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.56it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.40it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.34it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.13it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.18it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.12it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.22it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.23it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:02<00:00,  9.27it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.17it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.18it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.29it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.28it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.97225\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  40%|███▉      | 1384/3463 [06:39<09:49,  3.53batch/s, loss=0.0525]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.72it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.65it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.68it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.40it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.70it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  9.03it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.24it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.27it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.32it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.43it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.47it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.36it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.40it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.43it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.28it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.29it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.13it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.16it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.12it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.17it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.14it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.20it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:02<00:00,  9.24it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.14it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.16it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.23it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.18it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.974\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  60%|█████▉    | 2076/3463 [10:00<06:28,  3.57batch/s, loss=0.0293]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:07,  4.42it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.46it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.50it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.19it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.55it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.91it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.12it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.17it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.28it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.34it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.43it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.47it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.49it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.38it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.29it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.11it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.11it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.09it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.07it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.18it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.20it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.06it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.11it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.23it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.25it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.976\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  80%|███████▉  | 2768/3463 [13:22<03:20,  3.47batch/s, loss=0.0271]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.58it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.51it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.55it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.31it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.65it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.85it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.03it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.10it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.22it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.31it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.35it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.40it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.38it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.41it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.38it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.35it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.13it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.18it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.21it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.04it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.10it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.18it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.19it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.10it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.14it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.28it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.26it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.9785\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|█████████▉| 3460/3463 [16:43<00:00,  3.48batch/s, loss=0.0126]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.50it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.49it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.44it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.24it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.64it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.96it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.18it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.24it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.34it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.45it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.51it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.55it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.46it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.39it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.17it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.19it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.20it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.20it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.24it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.26it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.25it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.12it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.15it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.30it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.26it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98025\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|██████████| 3463/3463 [16:50<00:00,  3.43batch/s, loss=0.00795]\n","Epoch 1:  20%|█▉        | 692/3463 [03:16<13:11,  3.50batch/s, loss=0.00253]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.57it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.51it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.56it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.23it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.54it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.89it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.12it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.21it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.44it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.46it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.51it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.51it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.41it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.34it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.31it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.17it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.21it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.20it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.11it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.21it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.23it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.23it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.11it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.16it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.30it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.31it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.977\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1:  40%|███▉      | 1384/3463 [06:37<09:49,  3.53batch/s, loss=0.0157]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.47it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.45it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.50it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.16it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.52it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.87it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.14it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.21it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.28it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.35it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.24it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.34it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.38it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.40it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.34it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.31it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.00it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.04it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.17it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.12it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.15it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.19it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.22it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.24it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.08it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.00it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.08it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.10it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.981\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1:  60%|█████▉    | 2076/3463 [09:58<06:37,  3.49batch/s, loss=0.0591]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.68it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.67it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.67it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.42it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.75it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  9.01it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.21it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.18it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.30it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.46it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.47it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.50it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.55it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.56it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.45it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.40it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.19it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.21it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.25it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.25it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.16it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.16it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.10it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.17it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:02<00:00,  9.18it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.09it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.16it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.30it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.32it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.979\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1:  80%|███████▉  | 2768/3463 [13:19<03:17,  3.52batch/s, loss=0.0349]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.54it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.62it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.71it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.23it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.58it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.91it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.14it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.20it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.42it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.35it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.45it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.47it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.46it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.35it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.27it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.07it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.18it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.18it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.07it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.13it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.19it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.19it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.19it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.03it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.09it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.24it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.23it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|█████████▉| 3460/3463 [16:41<00:00,  3.42batch/s, loss=0.0442]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.64it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.60it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.51it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.30it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.58it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.92it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.13it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.15it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.31it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.39it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.43it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.40it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.45it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.51it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.43it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.35it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.34it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.10it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.13it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.00it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.04it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.03it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.09it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.10it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.04it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.12it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.25it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.23it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.97975\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 3463/3463 [16:46<00:00,  3.44batch/s, loss=0.066]\n","Epoch 2:  20%|█▉        | 692/3463 [03:17<13:14,  3.49batch/s, loss=0.0564]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.62it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.63it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.69it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.33it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.65it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.84it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.05it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.10it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.24it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.34it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.32it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.28it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.36it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.40it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.38it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.20it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.20it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.01it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.06it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.11it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.10it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.05it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.10it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.16it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.21it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.23it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.11it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.13it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.20it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.19it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  40%|███▉      | 1384/3463 [06:38<09:46,  3.54batch/s, loss=0.0259]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.59it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.62it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.61it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.26it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.60it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.85it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.07it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.15it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.28it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.35it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.41it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.36it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.41it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.45it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.50it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.47it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.37it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.32it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.11it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.05it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:01,  8.94it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  8.92it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  8.99it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.05it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.10it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.03it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.07it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.19it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.08it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98175\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  60%|█████▉    | 2076/3463 [09:59<06:36,  3.50batch/s, loss=0.106] \n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.60it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.63it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.68it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.36it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.68it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.98it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.17it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.25it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.34it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.42it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.45it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.36it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.39it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.37it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.42it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.35it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.32it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.09it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.10it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.12it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.06it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.11it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.13it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.13it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.12it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.04it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.10it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.22it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.21it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98175\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  80%|███████▉  | 2768/3463 [13:21<03:20,  3.47batch/s, loss=0.0346]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:06,  4.56it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.64it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.59it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.26it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.60it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.86it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.13it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.19it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.33it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.37it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.43it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.30it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.32it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.42it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.46it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.48it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.39it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.38it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.14it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.13it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.06it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.05it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:01,  8.98it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.01it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.10it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.17it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.16it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.06it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.10it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.20it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.14it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98225\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|█████████▉| 3460/3463 [16:42<00:00,  3.47batch/s, loss=0.0427] \n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:07,  4.41it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:04,  6.41it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:03,  7.53it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:03,  8.24it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:03,  8.62it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:00<00:02,  8.91it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:00<00:02,  9.13it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:00<00:02,  9.18it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:02,  9.31it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:02,  9.41it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:02,  9.45it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:01<00:02,  9.38it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:01<00:02,  9.39it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:01<00:01,  9.43it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:01<00:01,  9.48it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:01<00:01,  9.39it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:01<00:01,  9.34it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:02<00:01,  9.22it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:02<00:01,  9.02it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:02<00:01,  9.05it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:02<00:01,  9.06it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:02<00:01,  9.08it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:02<00:00,  9.05it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:02<00:00,  9.09it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:02<00:00,  9.14it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:02<00:00,  9.16it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:03<00:00,  9.18it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:03<00:00,  9.07it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:03<00:00,  9.11it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:03<00:00,  9.17it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:03<00:00,  9.16it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.98275\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 3463/3463 [16:47<00:00,  3.44batch/s, loss=0.00776]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","test_df = pd.read_csv('test_no_label.csv')"],"metadata":{"id":"P95gtlnurvgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = test_df['Id']"],"metadata":{"id":"cLDzC10ErvgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_id_file_test(tokenizer, test_dataset):\n","    data_strings = []\n","    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n","    for item in id_file_data:\n","        data_strings.append(' '.join([str(k) for k in item]))\n","    return data_strings"],"metadata":{"id":"jnt693N0rvgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = make_id_file_test(tokenizer, test_dataset)"],"metadata":{"id":"7C5PpXtlrvgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test[:10]"],"metadata":{"id":"1aqse7SHrvgY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af38c50f-8bf8-4802-80c1-433d3c4508f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['101 2009 1005 1055 1037 2878 2047 3325 1998 2047 26389 2169 2051 2017 2175 1012 102',\n"," '101 2061 15640 2013 2019 2214 5440 1012 102',\n"," '101 2009 2003 1996 2087 14469 7273 1999 1996 3028 1012 102',\n"," '101 2079 2025 3696 1037 10084 2007 2122 2111 1012 102',\n"," '101 1045 2001 6091 1998 2016 2081 2033 2514 2061 6625 1998 6160 1012 102',\n"," '101 1996 2069 2518 2057 2363 2008 2001 2980 2001 1996 4157 1012 102',\n"," '101 2053 1010 2025 1996 3924 2012 2004 2226 1010 1996 3924 1999 3502 2152 1012 102',\n"," '101 2027 3288 2009 2041 2392 2005 2017 1998 2024 2200 14044 1012 102',\n"," '101 4606 1996 12043 2106 1050 1005 1056 2130 2113 2129 2000 2147 1996 3274 1012 102',\n"," '101 2027 2031 2019 6581 4989 1997 25025 2015 2000 5454 2013 1012 102']"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["class SentimentTestDataset(object):\n","    def __init__(self, tokenizer, test):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","\n","        for sent in test:\n","            self.data += [self._cast_to_int(sent.strip().split())]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample)"],"metadata":{"id":"cZi14gnnrvgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = SentimentTestDataset(tokenizer, test)"],"metadata":{"id":"erHjGE9rrvgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn_style_test(samples):\n","    input_ids = samples\n","    max_len = max(len(input_id) for input_id in input_ids)\n","    sorted_indices = np.array([len(input_id) for input_id in input_ids])\n","\n","    input_ids = pad_sequence([torch.tensor(input_id) for input_id in input_ids],\n","                             batch_first=True)\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_id) + [0] * (max_len - len(input_id)) for input_id in\n","         input_ids])\n","    token_type_ids = torch.tensor([[0] * len(input_id) for input_id in input_ids])\n","    position_ids = torch.tensor([list(range(len(input_id))) for input_id in input_ids])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids"],"metadata":{"id":"y03-nDX9rvgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_batch_size = 32\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n","                                          shuffle=False, collate_fn=collate_fn_style_test,\n","                                          num_workers=2)"],"metadata":{"id":"gZ0l1HparvgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    model.eval()\n","    predictions = []\n","    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n","                                                                        desc='Test',\n","                                                                        position=1,\n","                                                                        leave=None):\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        position_ids = position_ids.to(device)\n","\n","        output = model(input_ids=input_ids,\n","                       attention_mask=attention_mask,\n","                       token_type_ids=token_type_ids,\n","                       position_ids=position_ids)\n","\n","        logits = output.logits\n","        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","        predictions += batch_predictions"],"metadata":{"id":"XoSHTbJUrvgZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"daa25ed1-29f4-4031-9fc3-7fd33847b73d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Test:   3%|▎         | 1/32 [00:00<00:04,  7.26it/s]\u001b[A\n","Test:  12%|█▎        | 4/32 [00:00<00:01, 18.61it/s]\u001b[A\n","Test:  22%|██▏       | 7/32 [00:00<00:01, 23.15it/s]\u001b[A\n","Test:  34%|███▍      | 11/32 [00:00<00:00, 27.15it/s]\u001b[A\n","Test:  47%|████▋     | 15/32 [00:00<00:00, 29.54it/s]\u001b[A\n","Test:  59%|█████▉    | 19/32 [00:00<00:00, 31.06it/s]\u001b[A\n","Test:  72%|███████▏  | 23/32 [00:00<00:00, 32.96it/s]\u001b[A\n","Test:  84%|████████▍ | 27/32 [00:00<00:00, 33.60it/s]\u001b[A\n","Test:  97%|█████████▋| 31/32 [00:01<00:00, 33.79it/s]\u001b[A\n","                                                     \u001b[A"]}]},{"cell_type":"code","source":["test_df['Category'] = predictions"],"metadata":{"id":"tGO3aS-VrvgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df.to_csv('submission.csv', index=False)"],"metadata":{"id":"VndXxal3rvgZ"},"execution_count":null,"outputs":[]}]}